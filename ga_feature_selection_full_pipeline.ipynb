{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_frac=0.01\n",
    "\n",
    "# Load dataset as pandas DataFrame\n",
    "df_train = pd.read_parquet('./data/cic_iomt_2024_wifi_mqtt_train.parquet')\n",
    "df_test = pd.read_parquet('./data/cic_iomt_2024_wifi_mqtt_test.parquet')  \n",
    "\n",
    "# Create sample DataFrame for feature selection\n",
    "df_train_sample = df_train.sample(frac=my_frac, random_state=1984)      \n",
    "df_test_sample = df_test.sample(frac=my_frac, random_state=1984)   \n",
    "\n",
    "# Create sample X and y from train and test, convert to numpy arrays\n",
    "X_train_sample = df_train_sample.drop(columns=['label', 'class_label', 'category_label', 'attack_label']).to_numpy()\n",
    "y_train_sample_2 = df_train_sample['class_label'].to_numpy()\n",
    "y_train_sample_6 = df_train_sample['category_label'].to_numpy()\n",
    "y_train_sample_19 = df_train_sample['attack_label'].to_numpy()\n",
    "\n",
    "\n",
    "X_test_sample = df_test_sample.drop(columns=['label', 'class_label', 'category_label', 'attack_label']).to_numpy()\n",
    "y_test_sample_2 = df_test_sample['class_label'].to_numpy()\n",
    "y_test_sample_6 = df_test_sample['category_label'].to_numpy()\n",
    "y_test_sample_19 = df_test_sample['attack_label'].to_numpy()\n",
    "\n",
    "\n",
    "# Create full data X and y from train and test, convert to numpy arrays\n",
    "X_train_full = df_train_sample.drop(columns=['label', 'class_label', 'category_label', 'attack_label']).to_numpy()\n",
    "y_train_full_2 = df_train_sample['class_label'].to_numpy()\n",
    "y_train_full_6 = df_train_sample['category_label'].to_numpy()\n",
    "y_train_full_19 = df_train_sample['attack_label'].to_numpy()\n",
    "\n",
    "\n",
    "X_test_full = df_test_sample.drop(columns=['label', 'class_label', 'category_label', 'attack_label']).to_numpy()\n",
    "y_test_full_2 = df_test_sample['class_label'].to_numpy()\n",
    "y_test_full_6 = df_test_sample['category_label'].to_numpy()\n",
    "y_test_full_19 = df_test_sample['attack_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use hyperparameters from the CICIoMT2024 to establish benchmarks for classification on the dataset. We will then use pso to select the best features and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_benchmark = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    dual=False, \n",
    "    tol=0.0001, \n",
    "    C=1.0, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    solver='lbfgs', \n",
    "    max_iter=100,\n",
    "    warm_start=False, \n",
    "    n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_benchmark.fit(X_train_sample, y_train_sample_2)\n",
    "y_pred_lr_benchmark_2 = lr_benchmark.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack       0.99      0.99      0.99     15803\n",
      "      Benign       0.54      0.45      0.50       339\n",
      "\n",
      "    accuracy                           0.98     16142\n",
      "   macro avg       0.77      0.72      0.74     16142\n",
      "weighted avg       0.98      0.98      0.98     16142\n",
      "\n",
      "Accuracy: 0.98055\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_lr_benchmark_2 = classification_report(y_test_sample_2, y_pred_lr_benchmark_2, output_dict=True)\n",
    "print(classification_report(y_test_sample_2, y_pred_lr_benchmark_2))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_lr_benchmark_2 = accuracy_score(y_test_sample_2, y_pred_lr_benchmark_2)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_lr_benchmark_2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_benchmark.fit(X_train_sample, y_train_sample_6)\n",
    "y_pred_lr_benchmark_6 = lr_benchmark.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.69      0.07      0.13       339\n",
      "        DDos       0.68      1.00      0.81     10633\n",
      "         Dos       0.08      0.00      0.00      4256\n",
      "        MQTT       0.15      0.02      0.03       623\n",
      "       Recon       0.00      0.00      0.00       274\n",
      "    Spoofing       0.03      0.47      0.05        17\n",
      "\n",
      "    accuracy                           0.66     16142\n",
      "   macro avg       0.27      0.26      0.17     16142\n",
      "weighted avg       0.49      0.66      0.54     16142\n",
      "\n",
      "Accuracy: 0.66119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_lr_benchmark_6 = classification_report(y_test_sample_6, y_pred_lr_benchmark_6, output_dict=True)\n",
    "print(classification_report(y_test_sample_6, y_pred_lr_benchmark_6))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_lr_benchmark_6 = accuracy_score(y_test_sample_6, y_pred_lr_benchmark_6)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_lr_benchmark_6:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19 Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_benchmark.fit(X_train_sample, y_train_sample_19)\n",
    "y_pred_lr_benchmark_19 = lr_benchmark.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      ARP_spoofing       0.00      0.00      0.00        17\n",
      "            Benign       0.54      0.53      0.54       339\n",
      "         DDoS_ICMP       0.00      0.00      0.00      3456\n",
      "          DDoS_SYN       0.00      0.00      0.00      1792\n",
      "          DDoS_TCP       0.00      0.00      0.00      1849\n",
      "          DDoS_UDP       0.22      1.00      0.37      3536\n",
      "DDoS_connect_flood       0.00      0.00      0.00       408\n",
      "DDoS_publish_flood       0.00      0.00      0.00        87\n",
      "          DoS_ICMP       0.00      0.00      0.00      1047\n",
      "           DoS_SYN       0.00      0.00      0.00      1007\n",
      "           DoS_TCP       0.00      0.00      0.00       852\n",
      "           DoS_UDP       0.00      0.00      0.00      1350\n",
      " DoS_connect_flood       0.00      0.00      0.00        30\n",
      " DoS_publish_flood       0.00      0.00      0.00        82\n",
      "    Malformed_date       0.00      0.00      0.00        16\n",
      "           OS_scan       0.00      0.00      0.00        32\n",
      "         Port_scan       0.00      0.00      0.00       223\n",
      "           VulScan       0.00      0.00      0.00        17\n",
      "        ping_sweep       0.00      0.00      0.00         2\n",
      "\n",
      "          accuracy                           0.23     16142\n",
      "         macro avg       0.04      0.08      0.05     16142\n",
      "      weighted avg       0.06      0.23      0.09     16142\n",
      "\n",
      "Accuracy: 0.23014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_lr_benchmark_19 = classification_report(y_test_sample_19, y_pred_lr_benchmark_19, output_dict=True)\n",
    "print(classification_report(y_test_sample_19, y_pred_lr_benchmark_19))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_lr_benchmark_19 = accuracy_score(y_test_sample_19, y_pred_lr_benchmark_19)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_lr_benchmark_19:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_benchmark = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(), \n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0, \n",
    "    algorithm='SAMME.R', \n",
    "    random_state=1984\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_benchmark.fit(X_train_sample, y_train_sample_2)\n",
    "y_pred_ada_benchmark_2 = ada_benchmark.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack       1.00      1.00      1.00     15803\n",
      "      Benign       0.96      0.94      0.95       339\n",
      "\n",
      "    accuracy                           1.00     16142\n",
      "   macro avg       0.98      0.97      0.98     16142\n",
      "weighted avg       1.00      1.00      1.00     16142\n",
      "\n",
      "Accuracy: 0.99802\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_ada_benchmark_2 = classification_report(y_test_sample_2, y_pred_ada_benchmark_2, output_dict=True)\n",
    "print(classification_report(y_test_sample_2, y_pred_ada_benchmark_2))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_ada_benchmark_2 = accuracy_score(y_test_sample_2, y_pred_ada_benchmark_2)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_ada_benchmark_2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_benchmark.fit(X_train_sample, y_train_sample_6)\n",
    "y_pred_ada_benchmark_6 = ada_benchmark.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.96      0.96      0.96       339\n",
      "        DDos       1.00      1.00      1.00     10633\n",
      "         Dos       1.00      1.00      1.00      4256\n",
      "        MQTT       1.00      0.99      1.00       623\n",
      "       Recon       0.96      0.96      0.96       274\n",
      "    Spoofing       0.63      0.71      0.67        17\n",
      "\n",
      "    accuracy                           1.00     16142\n",
      "   macro avg       0.93      0.94      0.93     16142\n",
      "weighted avg       1.00      1.00      1.00     16142\n",
      "\n",
      "Accuracy: 0.99783\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_ada_benchmark_6 = classification_report(y_test_sample_6, y_pred_ada_benchmark_6, output_dict=True)\n",
    "print(classification_report(y_test_sample_6, y_pred_ada_benchmark_6))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_ada_benchmark_6 = accuracy_score(y_test_sample_6, y_pred_ada_benchmark_6)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_ada_benchmark_6:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19 Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_benchmark.fit(X_train_sample, y_train_sample_19)\n",
    "y_pred_ada_benchmark_19 = ada_benchmark.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      ARP_spoofing       0.44      0.88      0.59        17\n",
      "            Benign       0.97      0.91      0.94       339\n",
      "         DDoS_ICMP       0.73      1.00      0.85      3456\n",
      "          DDoS_SYN       1.00      1.00      1.00      1792\n",
      "          DDoS_TCP       1.00      1.00      1.00      1849\n",
      "          DDoS_UDP       1.00      0.64      0.78      3536\n",
      "DDoS_connect_flood       1.00      1.00      1.00       408\n",
      "DDoS_publish_flood       1.00      0.09      0.17        87\n",
      "          DoS_ICMP       0.44      1.00      0.61      1047\n",
      "           DoS_SYN       1.00      1.00      1.00      1007\n",
      "           DoS_TCP       1.00      1.00      1.00       852\n",
      "           DoS_UDP       1.00      0.03      0.05      1350\n",
      " DoS_connect_flood       1.00      1.00      1.00        30\n",
      " DoS_publish_flood       0.51      0.99      0.67        82\n",
      "    Malformed_date       0.82      0.88      0.85        16\n",
      "           OS_scan       0.72      0.81      0.76        32\n",
      "         Port_scan       0.93      0.96      0.94       223\n",
      "           VulScan       1.00      0.59      0.74        17\n",
      "        ping_sweep       0.00      0.00      0.00         2\n",
      "\n",
      "          accuracy                           0.83     16142\n",
      "         macro avg       0.82      0.78      0.73     16142\n",
      "      weighted avg       0.90      0.83      0.80     16142\n",
      "\n",
      "Accuracy: 0.83137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report_ada_benchmark_19 = classification_report(y_test_sample_19, y_pred_ada_benchmark_19, output_dict=True)\n",
    "print(classification_report(y_test_sample_19, y_pred_ada_benchmark_19))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_ada_benchmark_19 = accuracy_score(y_test_sample_19, y_pred_ada_benchmark_19)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_ada_benchmark_19:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_benchmark = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    criterion='gini', \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0, \n",
    "    max_features='sqrt', \n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True, \n",
    "    oob_score=False, \n",
    "    warm_start=False, \n",
    "    ccp_alpha=0.0, \n",
    "    n_jobs=-1, \n",
    "    random_state=1984\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_benchmark.fit(X_train_sample, y_train_sample_2) \n",
    "y_pred_rf_benchmark_2 = rf_benchmark.predict(X_test_sample)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack       1.00      1.00      1.00     15803\n",
      "      Benign       0.96      0.94      0.95       339\n",
      "\n",
      "    accuracy                           1.00     16142\n",
      "   macro avg       0.98      0.97      0.97     16142\n",
      "weighted avg       1.00      1.00      1.00     16142\n",
      "\n",
      "Accuracy: 0.99796\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_rf_benchmark_2 = classification_report(y_test_sample_2, y_pred_rf_benchmark_2, output_dict=True)\n",
    "print(classification_report(y_test_sample_2, y_pred_rf_benchmark_2))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_rf_benchmark_2 = accuracy_score(y_test_sample_2, y_pred_rf_benchmark_2)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_rf_benchmark_2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_benchmark.fit(X_train_sample, y_train_sample_6) \n",
    "y_pred_rf_benchmark_6 = rf_benchmark.predict(X_test_sample)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.94      0.99      0.96       339\n",
      "        DDos       1.00      1.00      1.00     10633\n",
      "         Dos       1.00      1.00      1.00      4256\n",
      "        MQTT       1.00      0.99      1.00       623\n",
      "       Recon       0.99      0.95      0.97       274\n",
      "    Spoofing       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           1.00     16142\n",
      "   macro avg       0.94      0.93      0.93     16142\n",
      "weighted avg       1.00      1.00      1.00     16142\n",
      "\n",
      "Accuracy: 0.99789\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_rf_benchmark_6 = classification_report(y_test_sample_6, y_pred_rf_benchmark_6, output_dict=True)\n",
    "print(classification_report(y_test_sample_6, y_pred_rf_benchmark_6))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_rf_benchmark_6 = accuracy_score(y_test_sample_6, y_pred_rf_benchmark_6)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_rf_benchmark_6:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19 Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_benchmark.fit(X_train_sample, y_train_sample_19) \n",
    "y_pred_rf_benchmark_19 = rf_benchmark.predict(X_test_sample)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      ARP_spoofing       0.44      0.65      0.52        17\n",
      "            Benign       0.92      0.96      0.94       339\n",
      "         DDoS_ICMP       1.00      1.00      1.00      3456\n",
      "          DDoS_SYN       1.00      1.00      1.00      1792\n",
      "          DDoS_TCP       1.00      1.00      1.00      1849\n",
      "          DDoS_UDP       1.00      1.00      1.00      3536\n",
      "DDoS_connect_flood       1.00      1.00      1.00       408\n",
      "DDoS_publish_flood       1.00      0.09      0.17        87\n",
      "          DoS_ICMP       1.00      1.00      1.00      1047\n",
      "           DoS_SYN       1.00      1.00      1.00      1007\n",
      "           DoS_TCP       1.00      1.00      1.00       852\n",
      "           DoS_UDP       1.00      1.00      1.00      1350\n",
      " DoS_connect_flood       1.00      1.00      1.00        30\n",
      " DoS_publish_flood       0.51      1.00      0.67        82\n",
      "    Malformed_date       1.00      0.75      0.86        16\n",
      "           OS_scan       0.71      0.47      0.57        32\n",
      "         Port_scan       0.92      0.99      0.95       223\n",
      "           VulScan       1.00      0.12      0.21        17\n",
      "        ping_sweep       0.00      0.00      0.00         2\n",
      "\n",
      "          accuracy                           0.99     16142\n",
      "         macro avg       0.87      0.79      0.78     16142\n",
      "      weighted avg       0.99      0.99      0.99     16142\n",
      "\n",
      "Accuracy: 0.99027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "report_rf_benchmark_19 = classification_report(y_test_sample_19, y_pred_rf_benchmark_19, output_dict=True)\n",
    "print(classification_report(y_test_sample_19, y_pred_rf_benchmark_19))\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_rf_benchmark_19 = accuracy_score(y_test_sample_19, y_pred_rf_benchmark_19)\n",
    "\n",
    "# print accuracy with 5 decimal places\n",
    "print(f\"Accuracy: {accuracy_rf_benchmark_19:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection With GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm parameters\n",
    "population_size = 20            # number of individuals in the population\n",
    "n_generations = 50              # maximum number of generations\n",
    "mutation_rate = 0.1             # probability of mutation\n",
    "fitness_threshold = 1           # fitness goal (threshold for stopping)\n",
    "stagnation_limit = 5            # number of generations without improvement before stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the fitness function for evaluating feature subsets\n",
    "def fitness_function(individual):\n",
    "    # function selects the features based on the individual's genes - features with values > 0.5 are selected\n",
    "    selected_features = np.where(individual == 1)[0]  # select features based on individual genes\n",
    "    if len(selected_features) == 0:                   # avoid empty feature set\n",
    "        return 0\n",
    "    X_train_selected = X_train_sample[:, selected_features]\n",
    "    X_test_selected = X_test_sample[:, selected_features]\n",
    "\n",
    "    if CLASSIFIER == 'lr':\n",
    "        lr = LogisticRegression(**lr_benchmark.get_params())\n",
    "        lr.fit(X_train_selected, y_train_sample)\n",
    "        y_pred = lr.predict(X_test_selected)\n",
    "\n",
    "    elif CLASSIFIER == 'ada':\n",
    "        ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=1984)\n",
    "        ada.fit(X_train_selected, y_train_sample)               \n",
    "        y_pred = ada.predict(X_test_selected) \n",
    "    \n",
    "    elif CLASSIFIER == 'rf':\n",
    "        rf = RandomForestClassifier(**rf_benchmark.get_params())\n",
    "        rf.fit(X_train_selected, y_train_sample)               \n",
    "        y_pred = rf.predict(X_test_selected) \n",
    "\n",
    "    accuracy = accuracy_score(y_test_sample, y_pred)      \n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Population and Objects for Collecting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of features for individual length\n",
    "n_features = X_train.shape[1]   # number of features in dataset (45)\n",
    "\n",
    "# initialize population with random values between 0 and 1 (individuals represent feature subsets)\n",
    "# population = np.random.rand(population_size, n_features)\n",
    "population = np.random.randint(2, size=(population_size, n_features))\n",
    "\n",
    "# initialize variables to track the best fitness and stagnation count\n",
    "best_fitness_overall = 0\n",
    "best_individual_overall = None\n",
    "no_improvement_count = 0\n",
    "termination_reason = None  # To store the reason for termination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
